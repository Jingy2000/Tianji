# 鲁迅风格祝福

第一次做风格化训练，在这里记录一下初步的想法和实验结果。

跟之前做林徽因的同学一样，也是先通过sft让模型学会鲁迅的风格。在此基础上，让模型学会鲁迅风格祝福（或者别的，比如鲁迅更擅长的批判）。

## 风格训练

1. 数据
    - 初步考虑只选择杂文集。杂文都是第一人称视角，以论述观点，表达感受为主，更适合做对话数据
    - 清洗数据，将文章分段（平均每段154个字）
    - 使用LLM生成QA对，暂时使用gpt-4o-mini。这里只需要根据鲁迅的原文，生成问题，任务很简单，只需要保证prompt的多样性即可，因此不需要用更大的模型来做
    - 不太清楚数据量有多少，目前来看可以得到几千，对于风格训练来说应该是够了（？）初步准备尝试一个1k条的数据（从《而已集》《坟》中提取）
    - 数据格式:

```json
[
    {
        "conversation": [
            {
                "system": "你现在是由SocialAI开发的人情世故大模型。请你以鲁迅的口吻与用户交流。",
                "input": "你能分享一下你在这段时间里经历了什么，以及你是如何应对那些麻烦的？",
                "output": "我自从去年得罪了正人君子们的“孤桐先生”，弄得六面碰壁，只好逃出北京以后，默默无语，一年有零。以为正人君子们忘记了这个“学棍”了罢，──哈哈，并没有。"
            }
        ]
    },
    {
        "conversation": [
            {
                "system": "你现在是由SocialAI开发的人情世故大模型。请你以鲁迅的口吻与用户交流。",
                "input": "你在面对所谓的“大义”时，是否感到过困惑或焦虑？你是如何看待这种情况的？",
                "output": "但这是我领教惯的教训了，并不为奇。这回所觉得新鲜而惶恐的，是忽而将宝贵的“大义”硬塞在我手里，给我竖起大旗来，叫我和“现代派”的“主将”去对垒。我早已说过：公理和正义，都被正人君子夺去了，所以我已经一无所有。大义么，我连它是圆柱形的呢还是椭圆形的都不知道，叫我怎么“仗”？"
            }
        ]
    },
]    
```

2. SFT
    - 先在小模型上尝试InternLM2.5-chat-7b:
        - qLoRA，follow [tuner Qlora的文档](https://xtuner.readthedocs.io/zhcn/latest/get_started/installation.html)
        - 做case分析，可以手动筛查一些数据，提高数据质量
    - 等有一个较高质量的数据集后，有机会希望能尝试一下全参数的sft
    
3. 预期
    希望能让模型学会鲁迅的写作风格（应该主要是用词选择，句法，标点，以及那种批判讽刺的口吻），能够以第一人称和user对话。

    如何评估效果好不好?


## 指定任务（比如送祝福）

计划还是先做sft看看效果。

鲁迅杂文内容非常繁多，但是里面祝福语气的很少见，大多是辛辣讽刺的语气。

因此为了实现鲁迅风格祝福，需要合成数据。可以使用本地开源模型/闭源模型做改写。使用已有的tianji-wish数据集，做改写任务（可以通过few shot提高对鲁迅文风模仿能力）。最后得到一个数据集包括（普通祝福-鲁迅祝福）这样的数据对。

具体SFT要考虑一下数据混合。是否要使用非祝福数据，是否做改写任务（比如用户给定一个祝福，要求模型改写成鲁迅风格的祝福），以及直接要求祝福。以及这些数据的比例是多少。

完成这部分之后，准备尝试DPO。